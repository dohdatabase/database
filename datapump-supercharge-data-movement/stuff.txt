STUFF TO REMEMBER
- YouTube videos for each chapter

**************************************************************


    ```
    <copy>

    </copy>

    -- Be sure to hit RETURN
    ```

<details>
    <summary>*click to see the output*</summary>
    ``` text
    ```
    </details> 

**************************************************************

##### Faster Imports
* CONSTRAINT_NOVALIDATE and how to re-enable validation afterwards
* Automatic parallelism for index creation on import

##### Customizing Data Pump Jobs
DATA_OPTIONS & TRANSFORM parameters and their options

CONTENT=ALL DATA_ONLY METADATA_ONLY

##### Determining Import Success
Show how to compare source and target (objects and rows) using DBMS_COMPARISON.
Also, show a script to compare an export log versus an import log (when the source is not available).
Marcus D - log file analyzer

##### Monitoring, Troubleshooting and Tracing
New views in 23ai:
V_$DATAPUMP_PROCESSWAIT_INFO
V_$DATAPUMP_PROCESS_INFO
V_$DATAPUMP_SESSIONWAIT_INFO
Monitoring performace with V$SESSION_LONGOPS

Different trace levels and when to use it
take a look at awr or execute certain SQL queries when DP runs slow.

My Data Pump tracing recipe  

Use keep_master and query the master_table showing we can use it to check the total rows for each table that was exported vs imported

Important views: dba_datapump_jobs (also the user variant), dba_datapump_sessions

ABORT_STEP=1

master_only=YES

Interactive console commands
Attaching to a job
Using Interactive Mode to Stop and Reattach to a Job
Universal (backwardly compatible) client (and how you don't need the client if you use the API)
Interactive command line usage in all its forms: stop, start, adjust parallelism or tracing, status, skip current, etc

##### Upgrade, Downgrade and Convert
Export from 19c non-CDB - import directly into 23ai PDB

Going back to earlier releases
VERSION parameter and general interoperability and compatibility
How to use version parameter to export from higher release and import on lower release

##### Using DBMS_DATAPUMP and DBMS_METADATA
well for sure DP API. I never used it in ACS and always thought I can do everything with a PAR file and the binaries.
just showing how to use the DBMS_DATAPUMP API.

SQL trace and check trace file

DBMS_METADATA.GET_DDL
DBMS_METADATA_DIFF package especially the COMPARE_ALTER routines
The stuff in the developer package: DBMS_DEVELOPER.GET????


##########################################################################################################################################
##########################################################################################################################################
##########################################################################################################################################
##########################################################################################################################################
##########################################################################################################################################
##########################################################################################################################################
##########################################################################################################################################
##########################################################################################################################################
##########################################################################################################################################
##########################################################################################################################################
##########################################################################################################################################




##########################################################################################################################################
##########################################################################################################################################
##########################################################################################################################################
##########################################################################################################################################
##########################################################################################################################################
##########################################################################################################################################
##########################################################################################################################################
##########################################################################################################################################
##########################################################################################################################################
##########################################################################################################################################
##########################################################################################################################################





cat << 'EOF' | sudo -u oracle tee /home/oracle/scripts/dp-07-checksum-export.par > /dev/null
schemas=F1
reuse_dumpfiles=yes
directory=dpdir
logfile=dp-07-checksum-export.log
dumpfile=dp-07-checksum.dmp
metrics=yes
logtime=all
exclude=statistics
EOF

cat << 'EOF' | sudo -u oracle tee /home/oracle/scripts/dp-07-checksum-import.par > /dev/null
directory=dpdir
logfile=dp-07-checksum-import.log
dumpfile=dp-07-checksum.dmp
metrics=yes
logtime=all
remap_schema=F1:LAB7CHECKSUM
EOF